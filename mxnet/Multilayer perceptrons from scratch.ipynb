{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/mxnet/optimizer.py:136: UserWarning: WARNING: New optimizer mxnet.optimizer.NAG is overriding existing optimizer mxnet.optimizer.NAG\n",
      "  Optimizer.opt_registry[name].__name__))\n"
     ]
    }
   ],
   "source": [
    "# http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-scratch.html\n",
    "\n",
    "from __future__ import print_function\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import nd, autograd, gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_ctx = mx.cpu()\n",
    "model_ctx = mx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load mnist data\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "batch_size = 64\n",
    "num_examples = 60000\n",
    "def transform(data, label):\n",
    "    return data.astype(np.float32)/255, label.astype(np.float32)\n",
    "train_data = gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=True, transform=transform),\n",
    "                                      batch_size, shuffle=True)\n",
    "test_data = gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                                     batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allocate Params\n",
    "# http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-scratch.html#Allocate-parameters\n",
    "#######################\n",
    "#  Set some constants so it's easy to modify the network later\n",
    "#######################\n",
    "num_hidden = 256\n",
    "weight_scale = .01\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the first hidden layer\n",
    "#######################\n",
    "W1 = nd.random_normal(shape=(num_inputs, num_hidden), scale=weight_scale, ctx=model_ctx)\n",
    "b1 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=model_ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the second hidden layer\n",
    "#######################\n",
    "W2 = nd.random_normal(shape=(num_hidden, num_hidden), scale=weight_scale, ctx=model_ctx)\n",
    "b2 = nd.random_normal(shape=num_hidden, scale=weight_scale, ctx=model_ctx)\n",
    "\n",
    "#######################\n",
    "#  Allocate parameters for the output layer\n",
    "#######################\n",
    "W3 = nd.random_normal(shape=(num_hidden, num_outputs), scale=weight_scale, ctx=model_ctx)\n",
    "b3 = nd.random_normal(shape=num_outputs, scale=weight_scale, ctx=model_ctx)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate spece for params gradients\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation functions\n",
    "# http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-scratch.html#Activation-functions\n",
    "# rectified linear unit (ReLU):\n",
    "def relu(X):\n",
    "    return nd.maximum(X, nd.zeros_like(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical softmax and cross entropy\n",
    "def softmax(y_linear):\n",
    "    exp = nd.exp(y_linear-nd.max(y_linear))\n",
    "    partition = nd.nansum(exp, axis=0, exclude=True).reshape((-1, 1))\n",
    "    return exp / partition\n",
    "\n",
    "# improvement on old cross_entropy\n",
    "# http://gluon.mxnet.io/chapter03_deep-neural-networks/mlp-scratch.html#The-softmax-cross-entropy-loss-function\n",
    "def softmax_cross_entropy(yhat_linear, y):\n",
    "    return - nd.nansum(y * nd.log_softmax(yhat_linear), axis=0, exclude=True)\n",
    "\n",
    "# old c e function\n",
    "# def cross_entropy(yhat, y):\n",
    "#     return - nd.nansum(y * nd.log(yhat), axis=0, exclude=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all 3 layers stacked up\n",
    "def net(X):\n",
    "    #######################\n",
    "    #  Compute the first hidden layer\n",
    "    #######################\n",
    "    h1_linear = nd.dot(X, W1) + b1\n",
    "    h1 = relu(h1_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the second hidden layer\n",
    "    #######################\n",
    "    h2_linear = nd.dot(h1, W2) + b2\n",
    "    h2 = relu(h2_linear)\n",
    "\n",
    "    #######################\n",
    "    #  Compute the output layer.\n",
    "    #  We will omit the softmax function here\n",
    "    #  because it will be applied\n",
    "    #  in the softmax_cross_entropy loss\n",
    "    #######################\n",
    "    yhat_linear = nd.dot(h2, W3) + b3\n",
    "    return yhat_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "def SGD(params, lr):\n",
    "    for param in params:\n",
    "        param[:] = param - lr * param.grad\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def evaluate_accuracy(data_iterator, net):\n",
    "    numerator = 0.\n",
    "    denominator = 0.\n",
    "    for i, (data, label) in enumerate(data_iterator):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(model_ctx)\n",
    "        output = net(data)\n",
    "        predictions = nd.argmax(output, axis=1)\n",
    "        numerator += nd.sum(predictions == label)\n",
    "        denominator += data.shape[0]\n",
    "    return (numerator / denominator).asscalar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0. Loss: 1.23557546169, Train_acc 0.883183, Test_acc 0.8822\n",
      "Epoch 1. Loss: 0.334782772899, Train_acc 0.921267, Test_acc 0.9207\n",
      "Epoch 2. Loss: 0.227777026486, Train_acc 0.946833, Test_acc 0.9455\n",
      "Epoch 3. Loss: 0.165289376726, Train_acc 0.960917, Test_acc 0.9568\n",
      "Epoch 4. Loss: 0.128114886862, Train_acc 0.9655, Test_acc 0.9599\n",
      "Epoch 5. Loss: 0.104161829895, Train_acc 0.97535, Test_acc 0.9674\n",
      "Epoch 6. Loss: 0.0873585311055, Train_acc 0.97565, Test_acc 0.9677\n",
      "Epoch 7. Loss: 0.0751715123077, Train_acc 0.9802, Test_acc 0.9718\n",
      "Epoch 8. Loss: 0.064577267994, Train_acc 0.985067, Test_acc 0.973\n",
      "Epoch 9. Loss: 0.05684501602, Train_acc 0.98665, Test_acc 0.9742\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 10\n",
    "learning_rate = .001\n",
    "smoothing_constant = .01\n",
    "\n",
    "for e in range(epochs):\n",
    "    cumulative_loss = 0\n",
    "    for i, (data, label) in enumerate(train_data):\n",
    "        data = data.as_in_context(model_ctx).reshape((-1, 784))\n",
    "        label = label.as_in_context(model_ctx)\n",
    "        label_one_hot = nd.one_hot(label, 10)\n",
    "        with autograd.record():\n",
    "            output = net(data)\n",
    "            loss = softmax_cross_entropy(output, label_one_hot)\n",
    "        loss.backward()\n",
    "        SGD(params, learning_rate)\n",
    "        cumulative_loss += nd.sum(loss).asscalar()\n",
    "\n",
    "\n",
    "    test_accuracy = evaluate_accuracy(test_data, net)\n",
    "    train_accuracy = evaluate_accuracy(train_data, net)\n",
    "    print(\"Epoch %s. Loss: %s, Train_acc %s, Test_acc %s\" %\n",
    "          (e, cumulative_loss/num_examples, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109936080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model predictions are: \n",
      "[ 1.  8.  9.  1.  9.  0.  3.  8.  7.  9.]\n",
      "<NDArray 10 @cpu(0)>\n",
      "true labels : \n",
      "[ 1.  8.  9.  1.  9.  0.  3.  8.  7.  9.]\n",
      "<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# Using model for prediction\n",
    "import matplotlib.pyplot as plt\n",
    "# Define the function to do prediction\n",
    "def model_predict(net,data):\n",
    "    output = net(data)\n",
    "    return nd.argmax(output, axis=1)\n",
    "\n",
    "samples = 10\n",
    "\n",
    "# let's sample 10 random data points from the test set\n",
    "#sample_data = mx.gluon.data.DataLoader(mnist_test, samples, shuffle=True)\n",
    "sample_data = mx.gluon.data.DataLoader(mx.gluon.data.vision.MNIST(train=False, transform=transform),\n",
    "                              samples, shuffle=True)\n",
    "for i, (data, label) in enumerate(sample_data):\n",
    "    data = data.as_in_context(model_ctx)\n",
    "    im = nd.transpose(data,(1,0,2,3))\n",
    "    im = nd.reshape(im,(28,10*28,1))\n",
    "    imtiles = nd.tile(im, (1,1,3))\n",
    "\n",
    "    plt.imshow(imtiles.asnumpy())\n",
    "    plt.show()\n",
    "    pred=model_predict(net,data.reshape((-1,784)))\n",
    "    print('model predictions are:', pred)\n",
    "    print('true labels :', label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
